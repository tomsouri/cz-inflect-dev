accum_count:
- 4
accum_steps:
- 0
adam_beta2: '0.998'
attention_dropout:
- 0.2
avg_tok_max: 20
avg_tok_min: 3
batch_size: '1024'
batch_type: sents
bucket_size: '262144'
config: configs/Transformer_best.yaml
data: '{''corpus_1'': {''path_src'': ''data/cleaned/neural/train.src'', ''path_tgt'':
  ''data/cleaned/neural/train.tgt'', ''transforms'': [''filtertoolong'']}, ''valid'':
  {''path_src'': ''data/cleaned/neural/dev_small.src'', ''path_tgt'': ''data/cleaned/neural/dev_small.tgt'',
  ''transforms'': [''filtertoolong'']}}'
dec_layers: '6'
decay_method: noam
decoder_start_token: <s>
decoder_type: transformer
default_specials:
- <unk>
- <blank>
- <s>
- </s>
doc_length: 200
dropout:
- 0.2
dropout_steps:
- 0
enc_layers: '6'
encoder_type: transformer
fuzzy_corpus_ratio: 0.1
fuzzy_threshold: 70
fuzzy_token: "\uFF5Ffuzzy\uFF60"
fuzzymatch_max_length: 70
fuzzymatch_min_length: 4
gpu_ranks:
- 0
heads: '8'
hidden_size: '256'
insert_ratio: 0.0
isolated_tag: "\uFF5Fph_#_std\uFF60"
label_smoothing: '0.1'
langid: []
learn_subwords_size: 32000
learning_rate: '2'
mask_length: subword
mask_ratio: 0.0
max_context: 1
max_generator_batches: '2'
max_grad_norm: '0'
max_tags: 12
model_dtype: fp16
n_sample: -1
n_src_feats: 0
norm_numbers: true
norm_quote_commas: true
normalization: tokens
num_threads: 1
num_workers: '0'
optim: adam
paired_etag: "\uFF5Fph_#_end\uFF60"
paired_stag: "\uFF5Fph_#_beg\uFF60"
param_init: '0'
param_init_glorot: 'True'
penn: true
permute_sent_ratio: 0.0
poisson_lambda: 3.0
position_encoding: 'True'
post_remove_control_chars: false
pre_replace_unicode_punct: false
random_ratio: 0.0
replace_length: -1
report_every: '4000'
reversible_tokenization: joiner
rotate_ratio: 0.0
save_checkpoint_steps: '4000'
save_data: data/inner/onmt/example
scripts_nok: []
scripts_ok:
- Latin
- Common
seed: '3435'
skip_empty_level: warning
src_delimiter: "\uFF5Ffuzzy\uFF60"
src_lang: ''
src_onmttok_kwargs: '{''mode'': ''none''}'
src_prefix: ''
src_seq_length: '150'
src_subword_alpha: 0
src_subword_model: source.model
src_subword_nbest: 1
src_subword_type: none
src_subword_vocab: ''
src_suffix: ''
src_tgt_ratio: 2
src_vocab: data/log/evaluate_models/onmt/experiments/Transformer_best_v0.11_tutorial_batch1024_accumcount4_LR2_Wed_Jul_12_21:37:52_CEST_2023/vocab.src
src_vocab_size: '50000'
src_vocab_threshold: 0
switchout_temperature: 1.0
tags_corpus_ratio: 0.1
tgt_lang: ''
tgt_onmttok_kwargs: '{''mode'': ''none''}'
tgt_prefix: ''
tgt_seq_length: 192
tgt_subword_alpha: 0
tgt_subword_model: target.model
tgt_subword_nbest: 1
tgt_subword_type: none
tgt_subword_vocab: ''
tgt_suffix: ''
tgt_vocab: data/log/evaluate_models/onmt/experiments/Transformer_best_v0.11_tutorial_batch1024_accumcount4_LR2_Wed_Jul_12_21:37:52_CEST_2023/vocab.tgt
tgt_vocab_size: '50000'
tgt_vocab_threshold: 0
tm_delimiter: "\t"
tokendrop_temperature: 1.0
tokenmask_temperature: 1.0
train_steps: '40000'
transformer_ff: '2048'
transforms: []
upper_corpus_ratio: 0.01
valid_batch_size: '8192'
valid_steps: '4000'
vocab_sample_queue_size: 20
warmup_steps: '4000'
word_vec_size: '256'
world_size: '1'
