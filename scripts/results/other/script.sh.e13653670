usage: onmt_train [-h] [-config CONFIG] [-save_config SAVE_CONFIG] -data DATA
                  [-skip_empty_level {silent,warning,error}]
                  [-transforms {bart,sentencepiece,bpe,onmt_tokenize,filterfeats,inferfeats,filtertoolong,prefix,switchout,tokendrop,tokenmask} [{bart,sentencepiece,bpe,onmt_tokenize,filterfeats,inferfeats,filtertoolong,prefix,switchout,tokendrop,tokenmask} ...]]
                  [-save_data SAVE_DATA] [-overwrite] [-n_sample N_SAMPLE]
                  [-dump_transforms] -src_vocab SRC_VOCAB
                  [-tgt_vocab TGT_VOCAB] [-share_vocab]
                  [-src_feats_vocab SRC_FEATS_VOCAB]
                  [-src_vocab_size SRC_VOCAB_SIZE]
                  [-tgt_vocab_size TGT_VOCAB_SIZE]
                  [-vocab_size_multiple VOCAB_SIZE_MULTIPLE]
                  [-src_words_min_frequency SRC_WORDS_MIN_FREQUENCY]
                  [-tgt_words_min_frequency TGT_WORDS_MIN_FREQUENCY]
                  [--src_seq_length_trunc SRC_SEQ_LENGTH_TRUNC]
                  [--tgt_seq_length_trunc TGT_SEQ_LENGTH_TRUNC]
                  [-both_embeddings BOTH_EMBEDDINGS]
                  [-src_embeddings SRC_EMBEDDINGS]
                  [-tgt_embeddings TGT_EMBEDDINGS]
                  [-embeddings_type {GloVe,word2vec}]
                  [--permute_sent_ratio PERMUTE_SENT_RATIO]
                  [--rotate_ratio ROTATE_RATIO] [--insert_ratio INSERT_RATIO]
                  [--random_ratio RANDOM_RATIO] [--mask_ratio MASK_RATIO]
                  [--mask_length {subword,word,span-poisson}]
                  [--poisson_lambda POISSON_LAMBDA]
                  [--replace_length {-1,0,1}]
                  [-src_subword_model SRC_SUBWORD_MODEL]
                  [-tgt_subword_model TGT_SUBWORD_MODEL]
                  [-src_subword_nbest SRC_SUBWORD_NBEST]
                  [-tgt_subword_nbest TGT_SUBWORD_NBEST]
                  [-src_subword_alpha SRC_SUBWORD_ALPHA]
                  [-tgt_subword_alpha TGT_SUBWORD_ALPHA]
                  [-src_subword_vocab SRC_SUBWORD_VOCAB]
                  [-tgt_subword_vocab TGT_SUBWORD_VOCAB]
                  [-src_vocab_threshold SRC_VOCAB_THRESHOLD]
                  [-tgt_vocab_threshold TGT_VOCAB_THRESHOLD]
                  [-src_subword_type {none,sentencepiece,bpe}]
                  [-tgt_subword_type {none,sentencepiece,bpe}]
                  [-src_onmttok_kwargs SRC_ONMTTOK_KWARGS]
                  [-tgt_onmttok_kwargs TGT_ONMTTOK_KWARGS]
                  [--reversible_tokenization {joiner,spacer}]
                  [--prior_tokenization] [--src_seq_length SRC_SEQ_LENGTH]
                  [--tgt_seq_length TGT_SEQ_LENGTH] [--src_prefix SRC_PREFIX]
                  [--tgt_prefix TGT_PREFIX]
                  [-switchout_temperature SWITCHOUT_TEMPERATURE]
                  [-tokendrop_temperature TOKENDROP_TEMPERATURE]
                  [-tokenmask_temperature TOKENMASK_TEMPERATURE]
                  [--src_word_vec_size SRC_WORD_VEC_SIZE]
                  [--tgt_word_vec_size TGT_WORD_VEC_SIZE]
                  [--word_vec_size WORD_VEC_SIZE] [--share_decoder_embeddings]
                  [--share_embeddings] [--position_encoding] [-update_vocab]
                  [--feat_merge {concat,sum,mlp}]
                  [--feat_vec_size FEAT_VEC_SIZE]
                  [--feat_vec_exponent FEAT_VEC_EXPONENT]
                  [-model_task {seq2seq,lm}] [--model_type {text}]
                  [--model_dtype {fp32,fp16}]
                  [--encoder_type {rnn,brnn,ggnn,mean,transformer,cnn,transformer_lm}]
                  [--decoder_type {rnn,transformer,cnn,transformer_lm}]
                  [--freeze_encoder] [--freeze_decoder] [--layers LAYERS]
                  [--enc_layers ENC_LAYERS] [--dec_layers DEC_LAYERS]
                  [--hidden_size HIDDEN_SIZE] [--enc_hid_size ENC_HID_SIZE]
                  [--dec_hid_size DEC_HID_SIZE]
                  [--cnn_kernel_width CNN_KERNEL_WIDTH]
                  [--pos_ffn_activation_fn {relu,gelu}]
                  [--input_feed INPUT_FEED] [--bridge]
                  [--rnn_type {LSTM,GRU,SRU}]
                  [--context_gate {source,target,both}]
                  [--bridge_extra_node BRIDGE_EXTRA_NODE]
                  [--bidir_edges BIDIR_EDGES] [--state_dim STATE_DIM]
                  [--n_edge_types N_EDGE_TYPES] [--n_node N_NODE]
                  [--n_steps N_STEPS] [--src_ggnn_size SRC_GGNN_SIZE]
                  [--global_attention {dot,general,mlp,none}]
                  [--global_attention_function {softmax,sparsemax}]
                  [--self_attn_type SELF_ATTN_TYPE]
                  [--max_relative_positions MAX_RELATIVE_POSITIONS]
                  [--heads HEADS] [--transformer_ff TRANSFORMER_FF]
                  [--aan_useffn] [--add_qkvbias] [--lambda_align LAMBDA_ALIGN]
                  [--alignment_layer ALIGNMENT_LAYER]
                  [--alignment_heads ALIGNMENT_HEADS]
                  [--full_context_alignment] [--copy_attn]
                  [--copy_attn_type {dot,general,mlp,none}]
                  [--generator_function {softmax,sparsemax}]
                  [--copy_attn_force] [--reuse_copy_attn]
                  [--copy_loss_by_seqlength] [--coverage_attn]
                  [--lambda_coverage LAMBDA_COVERAGE]
                  [--lm_prior_model LM_PRIOR_MODEL]
                  [--lm_prior_lambda LM_PRIOR_LAMBDA]
                  [--lm_prior_tau LM_PRIOR_TAU] [--loss_scale LOSS_SCALE]
                  [--apex_opt_level {,O0,O1,O2,O3}] [--data_type DATA_TYPE]
                  [--save_model SAVE_MODEL]
                  [--save_checkpoint_steps SAVE_CHECKPOINT_STEPS]
                  [--keep_checkpoint KEEP_CHECKPOINT]
                  [--gpu_ranks [GPU_RANKS [GPU_RANKS ...]]]
                  [--world_size WORLD_SIZE] [--gpu_backend GPU_BACKEND]
                  [--gpu_verbose_level GPU_VERBOSE_LEVEL]
                  [--master_ip MASTER_IP] [--master_port MASTER_PORT]
                  [--seed SEED] [--param_init PARAM_INIT]
                  [--param_init_glorot] [--train_from TRAIN_FROM]
                  [--reset_optim {none,all,states,keep_states}]
                  [--pre_word_vecs_enc PRE_WORD_VECS_ENC]
                  [--pre_word_vecs_dec PRE_WORD_VECS_DEC]
                  [--freeze_word_vecs_enc] [--freeze_word_vecs_dec]
                  [--num_workers NUM_WORKERS] [--batch_size BATCH_SIZE]
                  [--batch_size_multiple BATCH_SIZE_MULTIPLE]
                  [--batch_type {sents,tokens}]
                  [--normalization {sents,tokens}]
                  [--accum_count ACCUM_COUNT [ACCUM_COUNT ...]]
                  [--accum_steps ACCUM_STEPS [ACCUM_STEPS ...]]
                  [--valid_steps VALID_STEPS]
                  [--valid_batch_size VALID_BATCH_SIZE]
                  [--train_steps TRAIN_STEPS] [--single_pass]
                  [--early_stopping EARLY_STOPPING]
                  [--early_stopping_criteria [EARLY_STOPPING_CRITERIA [EARLY_STOPPING_CRITERIA ...]]]
                  [--optim {sgd,adagrad,adadelta,adam,sparseadam,adafactor,fusedadam}]
                  [--adagrad_accumulator_init ADAGRAD_ACCUMULATOR_INIT]
                  [--max_grad_norm MAX_GRAD_NORM]
                  [--dropout DROPOUT [DROPOUT ...]]
                  [--attention_dropout ATTENTION_DROPOUT [ATTENTION_DROPOUT ...]]
                  [--dropout_steps DROPOUT_STEPS [DROPOUT_STEPS ...]]
                  [--truncated_decoder TRUNCATED_DECODER]
                  [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]
                  [--label_smoothing LABEL_SMOOTHING]
                  [--average_decay AVERAGE_DECAY]
                  [--average_every AVERAGE_EVERY]
                  [--learning_rate LEARNING_RATE]
                  [--learning_rate_decay LEARNING_RATE_DECAY]
                  [--start_decay_steps START_DECAY_STEPS]
                  [--decay_steps DECAY_STEPS]
                  [--decay_method {noam,noamwd,rsqrt,none}]
                  [--warmup_steps WARMUP_STEPS] [--log_file LOG_FILE]
                  [--log_file_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET,50,40,30,20,10,0}]
                  [--verbose] [--train_eval_steps TRAIN_EVAL_STEPS]
                  [--train_metrics TRAIN_METRICS [TRAIN_METRICS ...]]
                  [--valid_metrics VALID_METRICS [VALID_METRICS ...]]
                  [--scoring_debug] [--dump_preds DUMP_PREDS]
                  [--report_every REPORT_EVERY] [--exp_host EXP_HOST]
                  [--exp EXP] [--tensorboard]
                  [--tensorboard_log_dir TENSORBOARD_LOG_DIR]
                  [-bucket_size BUCKET_SIZE]
                  [-bucket_size_init BUCKET_SIZE_INIT]
                  [-bucket_size_increment BUCKET_SIZE_INCREMENT]
                  [-prefetch_factor PREFETCH_FACTOR]
onmt_train: error: Unable to open config file: onmt.yaml. Error: No such file or directory
usage: onmt_translate [-h] [-config CONFIG] [-save_config SAVE_CONFIG] --model
                      MODEL [MODEL ...] [--fp32] [--int8] [--avg_raw_probs]
                      [--data_type DATA_TYPE] --src SRC [-src_feats SRC_FEATS]
                      [--tgt TGT] [--tgt_file_prefix] [--output OUTPUT]
                      [--report_align] [--report_time] [--beam_size BEAM_SIZE]
                      [--ratio RATIO]
                      [--random_sampling_topk RANDOM_SAMPLING_TOPK]
                      [--random_sampling_topp RANDOM_SAMPLING_TOPP]
                      [--random_sampling_temp RANDOM_SAMPLING_TEMP]
                      [--seed SEED] [--length_penalty {none,wu,avg}]
                      [--alpha ALPHA] [--coverage_penalty {none,wu,summary}]
                      [--beta BETA] [--stepwise_penalty]
                      [--min_length MIN_LENGTH] [--max_length MAX_LENGTH]
                      [--block_ngram_repeat BLOCK_NGRAM_REPEAT]
                      [--ignore_when_blocking IGNORE_WHEN_BLOCKING [IGNORE_WHEN_BLOCKING ...]]
                      [--replace_unk] [--ban_unk_token]
                      [--phrase_table PHRASE_TABLE] [--log_file LOG_FILE]
                      [--log_file_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET,50,40,30,20,10,0}]
                      [--verbose] [--attn_debug] [--align_debug]
                      [--dump_beam DUMP_BEAM] [--n_best N_BEST] [--with_score]
                      [--batch_size BATCH_SIZE] [--batch_type {sents,tokens}]
                      [--gpu GPU]
                      [-transforms {bart,sentencepiece,bpe,onmt_tokenize,filterfeats,inferfeats,filtertoolong,prefix,switchout,tokendrop,tokenmask} [{bart,sentencepiece,bpe,onmt_tokenize,filterfeats,inferfeats,filtertoolong,prefix,switchout,tokendrop,tokenmask} ...]]
                      [--permute_sent_ratio PERMUTE_SENT_RATIO]
                      [--rotate_ratio ROTATE_RATIO]
                      [--insert_ratio INSERT_RATIO]
                      [--random_ratio RANDOM_RATIO] [--mask_ratio MASK_RATIO]
                      [--mask_length {subword,word,span-poisson}]
                      [--poisson_lambda POISSON_LAMBDA]
                      [--replace_length {-1,0,1}]
                      [-src_subword_model SRC_SUBWORD_MODEL]
                      [-tgt_subword_model TGT_SUBWORD_MODEL]
                      [-src_subword_nbest SRC_SUBWORD_NBEST]
                      [-tgt_subword_nbest TGT_SUBWORD_NBEST]
                      [-src_subword_alpha SRC_SUBWORD_ALPHA]
                      [-tgt_subword_alpha TGT_SUBWORD_ALPHA]
                      [-src_subword_vocab SRC_SUBWORD_VOCAB]
                      [-tgt_subword_vocab TGT_SUBWORD_VOCAB]
                      [-src_vocab_threshold SRC_VOCAB_THRESHOLD]
                      [-tgt_vocab_threshold TGT_VOCAB_THRESHOLD]
                      [-src_subword_type {none,sentencepiece,bpe}]
                      [-tgt_subword_type {none,sentencepiece,bpe}]
                      [-src_onmttok_kwargs SRC_ONMTTOK_KWARGS]
                      [-tgt_onmttok_kwargs TGT_ONMTTOK_KWARGS]
                      [--reversible_tokenization {joiner,spacer}]
                      [--prior_tokenization] [--src_seq_length SRC_SEQ_LENGTH]
                      [--tgt_seq_length TGT_SEQ_LENGTH]
                      [--src_prefix SRC_PREFIX] [--tgt_prefix TGT_PREFIX]
                      [-switchout_temperature SWITCHOUT_TEMPERATURE]
                      [-tokendrop_temperature TOKENDROP_TEMPERATURE]
                      [-tokenmask_temperature TOKENMASK_TEMPERATURE]
onmt_translate: error: unrecognized arguments: Dec 15 03:08:13 CET 2022.txt
